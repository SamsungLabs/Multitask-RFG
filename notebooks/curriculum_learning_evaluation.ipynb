{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## In this notebook, we run evaluation on curriculum learning \n",
    "## model using predicted tags. \n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from mtrfg.utils import load_json, dict_as_readable_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get all dir paths for curriculum learning models.\n",
    "\n",
    "curriculum_models = glob.glob(\"../saved_models/curriculum_learning_models/train_bin_by_bin/*/model.pth\")\n",
    "curriculum_models_dirs = [Path(model_path).parent.absolute() for model_path in curriculum_models]\n",
    "curriculum_models_dirs.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test file path\n",
    "test_file = '/data/Ahmad/Silver/Parser/test.conllu'\n",
    "test_file_out = 'silver_test_out.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's evaluate! \n",
    "for dir_path in curriculum_models_dirs:\n",
    "    cmd = f'CUDA_VISIBLE_DEVICE=2 python3 ../tools/evaluate.py --opts --dir_name \"{dir_path}\" --test_file \"{test_file}\" --batch_size \"16\" --save_file_name \"{test_file_out}\" --use_pred_tags \"True\"'\n",
    "    if os.system(cmd) != 0:\n",
    "        print(\"Evaluation failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## time to gather the results\n",
    "\n",
    "result_files_list = [os.path.join(model_dir, test_file_out) for model_dir in curriculum_models_dirs]\n",
    "all_results = {f'bin_{i}': load_json(file_path) for i, file_path in enumerate(result_files_list)}\n",
    "\n",
    "## let's get the results\n",
    "parser_labeled_results = {key: value['parser_labeled_results'] for key, value in all_results.items()}\n",
    "tagger_results = {key: value['tagger_results'] for key, value in all_results.items()}\n",
    "parser_unlabeled_results = {key: value['parser_unlabeled_results'] for key, value in all_results.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parser labeled results:\n",
      "bin_0 : OrderedDict([('P', 0.3821), ('R', 0.4161), ('F1', 0.3984)])\n",
      "bin_1 : OrderedDict([('P', 0.5244), ('R', 0.5759), ('F1', 0.5489)])\n",
      "bin_2 : OrderedDict([('P', 0.463), ('R', 0.6766), ('F1', 0.5498)])\n",
      "bin_3 : OrderedDict([('P', 0.4728), ('R', 0.7122), ('F1', 0.5683)])\n",
      "bin_4 : OrderedDict([('P', 0.3803), ('R', 0.7305), ('F1', 0.5002)])\n",
      "bin_5 : OrderedDict([('P', 0.3331), ('R', 0.7491), ('F1', 0.4612)])\n",
      "bin_6 : OrderedDict([('P', 0.3803), ('R', 0.7704), ('F1', 0.5093)])\n",
      "bin_7 : OrderedDict([('P', 0.3138), ('R', 0.7854), ('F1', 0.4484)])\n",
      "bin_8 : OrderedDict([('P', 0.3206), ('R', 0.7894), ('F1', 0.456)])\n",
      "bin_9 : OrderedDict([('P', 0.3243), ('R', 0.7952), ('F1', 0.4607)])\n",
      "Parser unlabeled results:\n",
      "bin_0 : OrderedDict([('P', 0.4196), ('R', 0.4569), ('F1', 0.4374)])\n",
      "bin_1 : OrderedDict([('P', 0.5627), ('R', 0.6179), ('F1', 0.589)])\n",
      "bin_2 : OrderedDict([('P', 0.4941), ('R', 0.722), ('F1', 0.5867)])\n",
      "bin_3 : OrderedDict([('P', 0.5038), ('R', 0.759), ('F1', 0.6056)])\n",
      "bin_4 : OrderedDict([('P', 0.4043), ('R', 0.7767), ('F1', 0.5318)])\n",
      "bin_5 : OrderedDict([('P', 0.3537), ('R', 0.7954), ('F1', 0.4897)])\n",
      "bin_6 : OrderedDict([('P', 0.4034), ('R', 0.8172), ('F1', 0.5402)])\n",
      "bin_7 : OrderedDict([('P', 0.3317), ('R', 0.8301), ('F1', 0.474)])\n",
      "bin_8 : OrderedDict([('P', 0.339), ('R', 0.8347), ('F1', 0.4821)])\n",
      "bin_9 : OrderedDict([('P', 0.3429), ('R', 0.841), ('F1', 0.4872)])\n",
      "Tagger results:\n",
      "bin_0 : OrderedDict([('P', 0.909), ('R', 0.8872), ('F1', 0.8979)])\n",
      "bin_1 : OrderedDict([('P', 0.9196), ('R', 0.9159), ('F1', 0.9178)])\n",
      "bin_2 : OrderedDict([('P', 0.9238), ('R', 0.9262), ('F1', 0.925)])\n",
      "bin_3 : OrderedDict([('P', 0.9339), ('R', 0.9267), ('F1', 0.9303)])\n",
      "bin_4 : OrderedDict([('P', 0.9327), ('R', 0.9351), ('F1', 0.9339)])\n",
      "bin_5 : OrderedDict([('P', 0.935), ('R', 0.9365), ('F1', 0.9357)])\n",
      "bin_6 : OrderedDict([('P', 0.9363), ('R', 0.9379), ('F1', 0.9371)])\n",
      "bin_7 : OrderedDict([('P', 0.9383), ('R', 0.9421), ('F1', 0.9402)])\n",
      "bin_8 : OrderedDict([('P', 0.9387), ('R', 0.9418), ('F1', 0.9402)])\n",
      "bin_9 : OrderedDict([('P', 0.9411), ('R', 0.9438), ('F1', 0.9424)])\n"
     ]
    }
   ],
   "source": [
    "print(f'Parser labeled results:\\n{dict_as_readable_string(parser_labeled_results)}')\n",
    "print(f'Parser unlabeled results:\\n{dict_as_readable_string(parser_unlabeled_results)}')\n",
    "print(f'Tagger results:\\n{dict_as_readable_string(tagger_results)}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "46e1864029c28752d956e1c306007726d1cdf9327c2678741762de7d12d39fb4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('MTrfg_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
