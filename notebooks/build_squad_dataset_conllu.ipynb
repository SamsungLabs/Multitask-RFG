{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    For parser input, the end of out answer will have head \\n    as start of our answer, that means last I-ANS will have\\n    B-ANS as head of it, and the entire phrase will be connected\\n    in that way. So we are predicting answer as a phrase in \\n    tagging, and also predicting it in parser. \\n    Though in theory, only tagger should work for the same. \\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## How tagger input is built?\n",
    "\n",
    "\"\"\"\n",
    "    This notebook will load squad_v2 dataset and put it as \n",
    "    conllu, each answer phrase will start with B-ANS \n",
    "    followed by I-ANS and end with O tag. Rest of the \n",
    "    tags are also going to be O tags.\n",
    "\"\"\"\n",
    "\n",
    "## How Parser input is built?\n",
    "\n",
    "\"\"\"\n",
    "    For parser input, the end of out answer will have head \n",
    "    as start of our answer, that means last I-ANS will have\n",
    "    B-ANS as head of it, and the entire phrase will be connected\n",
    "    in that way. So we are predicting answer as a phrase in \n",
    "    tagging, and also predicting it in parser. \n",
    "    Though in theory, only tagger should work for the same. \n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports\n",
    "from datasets import load_dataset\n",
    "from mtrfg.utils import write_text, make_dir, load_json\n",
    "from tqdm import tqdm\n",
    "import spacy, re, string, random, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's load the spacy tokenizer\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "nlp.tokenizer = spacy.tokenizer.Tokenizer(nlp.vocab, suffix_search = re.compile(r'''\\.|\\,|\\;|\\(|\\)|\\$''').search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad_v2 (/user/d.bhatt/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d)\n",
      "100%|██████████| 2/2 [00:00<00:00, 1107.11it/s]\n"
     ]
    }
   ],
   "source": [
    "## load squad_v2 from huggingface hub\n",
    "dataset_name = 'squad_v2'\n",
    "dataset = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write a function to turn a question, context and answer into a CoNLLU format. \n",
    "def get_que_ans_in_conllu(data_point):\n",
    "    \"\"\"\n",
    "        We get squad_v2 datapoint as input\n",
    "        and turn it into a CoNLLU format, we do \n",
    "        the following.\n",
    "        1. As [CLS] token, followed by tokenized query\n",
    "        2. [SEP] token after tokenized query\n",
    "        3. Context token after [SEP] token\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "        Here we have everything in try and except block, because \n",
    "        there are some places where answers are incomplete, or\n",
    "        answers are not present and so on, we don't want such \n",
    "        questions for our model, so we filter them out. \n",
    "    \"\"\"\n",
    "    try:\n",
    "\n",
    "        ## only keep printable characters\n",
    "        data_point['answers']['text'][0] = ''.join([char for char in data_point['answers']['text'][0] if char in string.printable])\n",
    "        data_point['context'] = ''.join([char for char in data_point['context'] if char in string.printable])\n",
    "        data_point['question'] = ''.join([char for char in data_point['question'] if char in string.printable])\n",
    "\n",
    "        ## let's mask out the answer\n",
    "        ans_len = len(data_point['answers']['text'][0])\n",
    "        ans_start = data_point['answers']['answer_start'][0]\n",
    "        ans_end = ans_start + ans_len\n",
    "\n",
    "        masked_context = data_point['context'][0:ans_start] + \"ANSWERMASK\" + data_point['context'][ans_end:]\n",
    "        question = data_point['question']\n",
    "        \n",
    "        ## remove characters which are not printable, so that they don't make a mess. \n",
    "        # context_unprintable = [char for char in masked_context if char not in string.printable]\n",
    "        # question_unprintable = [char for char in question if char not in string.printable]\n",
    "        # for chara in context_unprintable:\n",
    "        #     masked_context = masked_context.replace(chara, '')    \n",
    "        # for chara in question_unprintable:\n",
    "        #     question = question.replace(chara, '')    \n",
    "\n",
    "        ## let's space out all the punctuations, and remove other whitespaces\n",
    "        for punc in string.punctuation:\n",
    "            masked_context = masked_context.replace(punc, f' {punc} ')    \n",
    "            question = question.replace(punc, f' {punc} ')    \n",
    "        \n",
    "        ## removing whitespace that could mess up data generation\n",
    "        for ws in string.whitespace[1:]:\n",
    "            masked_context = masked_context.replace(ws, '')    \n",
    "            question = question.replace(ws, '')\n",
    "\n",
    "        ## tokenize question and masked context\n",
    "        que_tokenized, context_tokenized, ans_tokenized = [[word.text] for word in nlp(question)], [[word.text] for word in nlp(masked_context)], [word.text for word in nlp(data_point['answers']['text'][0]) ]\n",
    "\n",
    "        ## get question and context as a list, use [SEP] token to separate question and contexts\n",
    "        que_context_as_list = que_tokenized + [['[SEP]']] + context_tokenized\n",
    "\n",
    "        ## remove whitespace tokens from the list\n",
    "        que_context_as_list = [token for token in que_context_as_list if len(token[0].replace(' ', '')) >  0]\n",
    "\n",
    "        ## tag list, edge list and head_list\n",
    "        que_context_tags, que_context_edges, que_context_heads = [['O'] for i in range(len(que_context_as_list))], [['root'] for i in range(len(que_context_as_list))], [[0] for i in range(len(que_context_as_list))]\n",
    "\n",
    "        ## index where answer is located!    \n",
    "        ans_index = que_context_as_list.index(['ANSWERMASK'])\n",
    "        \n",
    "        ## head of the start of the answer\n",
    "        ans_head = ans_index + len(ans_tokenized) ## heads are 1 indexed, last token of the answer is where first token of the answer points to\n",
    "\n",
    "        ## answer tags, heads, edges\n",
    "        ans_tags, ans_heads, ans_edges = ['B-ANS'] + ['I-ANS'] * (len(ans_tokenized) - 1), [ans_head] + [0] * (len(ans_tokenized) - 1), ['e'] + ['root'] * (len(ans_tokenized) - 1)\n",
    "        \n",
    "        ## let's get the actual answer\n",
    "        que_context_as_list[ans_index] = ans_tokenized\n",
    "        que_context_tags[ans_index] = ans_tags\n",
    "        que_context_edges[ans_index] = ans_edges\n",
    "        que_context_heads[ans_index] = ans_heads\n",
    "\n",
    "        ## let's collapse the list of lists as lists\n",
    "        que_context_as_list = [token if token is not None else '[NEW]' for token_list in que_context_as_list for token in token_list]\n",
    "        que_context_tags = [token if token is not None else 'O' for token_list in que_context_tags for token in token_list]\n",
    "        que_context_edges = [token if token is not None else 'root' for token_list in que_context_edges for token in token_list]\n",
    "        que_context_heads = [token if token is not None else 0 for token_list in que_context_heads for token in token_list]\n",
    "        \n",
    "        ## que_context as string\n",
    "        que_context_as_string = []\n",
    "        i = 0\n",
    "        for token, tag, edge, head in zip(que_context_as_list, que_context_tags, que_context_edges, que_context_heads):\n",
    "            if not token.isspace():\n",
    "                que_context_as_string.append(f'{i+1}\\t{token}\\t_\\t_\\t{tag}\\t_\\t{head}\\t{edge}\\t_\\t_')\n",
    "                i += 1\n",
    "\n",
    "        que_context_as_string = '\\n'.join(que_context_as_string)\n",
    "\n",
    "        return que_context_as_string\n",
    "    \n",
    "    except:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 707/130319 [00:17<49:34, 43.58it/s]  "
     ]
    }
   ],
   "source": [
    "## get all squad question/answers in CoNLLU format\n",
    "squad_train_conllu = [get_que_ans_in_conllu(datapoint) for datapoint in tqdm(dataset['train'])]\n",
    "squad_validation_conllu = [get_que_ans_in_conllu(datapoint) for datapoint in tqdm(dataset['validation'])]\n",
    "\n",
    "## let's filter out None\n",
    "squad_train_conllu = [train_point for train_point in squad_train_conllu if train_point is not None]\n",
    "squad_validation_conllu = [val_point for val_point in squad_validation_conllu if val_point is not None]\n",
    "\n",
    "## let's create a test dataset from train dataset as squad doesn't have any test dataset\n",
    "## create testdatset of same size as validation dataset\n",
    "random.shuffle(squad_train_conllu)\n",
    "\n",
    "## test dataset \n",
    "squad_test_conllu = squad_train_conllu[-len(squad_validation_conllu):] \n",
    "squad_train_conllu = squad_train_conllu[:-len(squad_validation_conllu)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the dataset\n",
    "# squad_data_dir = '/data/Multitask_RFG/squad_conllu_dataset_without_CLS/' ## data directory\n",
    "# make_dir(squad_data_dir) \n",
    "# train_file, test_file, val_file = os.path.join(squad_data_dir, 'train.conllu'), os.path.join(squad_data_dir, 'test.conllu'), os.path.join(squad_data_dir, 'dev.conllu')\n",
    "\n",
    "# ## saving\n",
    "# write_text(train_file, '\\n\\n'.join(squad_train_conllu))\n",
    "# write_text(test_file, '\\n\\n'.join(squad_test_conllu))\n",
    "# write_text(val_file, '\\n\\n'.join(squad_validation_conllu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## time to build recipe QA dataset\n",
    "def buildDataPoint(question, recipe, answer):\n",
    "    ### we have to build datapoint in a way that'd be able to pass it to the processing pipeline\n",
    "    question, recipe, answer = question.lower(), recipe.lower(), answer.lower() ## everything lowercase must\n",
    "    answer_start = recipe.find(answer)\n",
    "    answer_end = len(answer) + answer_start\n",
    "    assert recipe[answer_start: answer_end] == answer\n",
    "    datapoint = {}\n",
    "    datapoint['question'] = question \n",
    "    datapoint['answers'] = {}\n",
    "    datapoint['answers']['text'] = [answer]\n",
    "    datapoint['answers']['answer_start'] = [answer_start]\n",
    "    datapoint['context'] = recipe\n",
    "\n",
    "    return datapoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading dataset!\n",
    "filePath = '/user/d.bhatt/video_summarization_in_text/youcook2/youcookii_annotations_trainval.json'\n",
    "recipeQA_data = load_json(filePath)['database']\n",
    "\n",
    "## let's get question answers\n",
    "questions, answers, context = [], [], []\n",
    "\n",
    "for videoID in recipeQA_data:\n",
    "    for segment in recipeQA_data[videoID]['segments']:\n",
    "        for question in recipeQA_data[videoID]['segments'][segment]:\n",
    "            ## getting questions, answers and context\n",
    "            recipe = recipeQA_data[videoID]['context']\n",
    "            if (isinstance(question, str) and isinstance(recipe, str) and isinstance(segment, str)):\n",
    "                questions.append(question)\n",
    "                answers.append(segment)\n",
    "                context.append(recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for question, recipe, answer in zip(questions, context, answers):\n",
    "    if not (isinstance(question, str) and isinstance(recipe, str) and isinstance(answer, str)):\n",
    "        print(question, recipe, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "53207it [00:00, 171132.61it/s]\n",
      "100%|██████████| 53207/53207 [13:29<00:00, 65.72it/s]\n"
     ]
    }
   ],
   "source": [
    "## building QA dataset in CoNLLU\n",
    "dataDict = [buildDataPoint(question, recipe, answer) for question, recipe, answer in tqdm(zip(questions, context, answers))]\n",
    "\n",
    "## data in CoNLLU format\n",
    "dataConLLU = [get_que_ans_in_conllu(dataPoint) for dataPoint in tqdm(dataDict)]\n",
    "\n",
    "## Filtering out None\n",
    "dataConLLU = [dataPoint for dataPoint in dataConLLU if dataPoint is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train, test, validation splits! 70% train, 15% validation, 15% train\n",
    "trainFrac, testFrac, valFrac = 70, 15, 15\n",
    "random.shuffle(dataConLLU)\n",
    "\n",
    "## indices to split the data\n",
    "train_index, test_index = len(dataConLLU) * trainFrac // 100, len(dataConLLU) * (trainFrac + valFrac) // 100 \n",
    "\n",
    "## train, test, validation splits!\n",
    "trainData, valData, testData = dataConLLU[:train_index], dataConLLU[train_index:test_index], dataConLLU[test_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the dataset\n",
    "recipe_data_dir = '/data/Multitask_RFG/recipeQAGPTdataset/' ## data directory\n",
    "make_dir(recipe_data_dir) \n",
    "train_file, test_file, val_file = os.path.join(recipe_data_dir, 'train.conllu'), os.path.join(recipe_data_dir, 'test.conllu'), os.path.join(recipe_data_dir, 'dev.conllu')\n",
    "\n",
    "## saving\n",
    "write_text(train_file, '\\n\\n'.join(trainData))\n",
    "write_text(test_file, '\\n\\n'.join(testData))\n",
    "write_text(val_file, '\\n\\n'.join(valData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37244 7982 7981\n"
     ]
    }
   ],
   "source": [
    "print(len(trainData), len(testData), len(valData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "46e1864029c28752d956e1c306007726d1cdf9327c2678741762de7d12d39fb4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('MTrfg_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
